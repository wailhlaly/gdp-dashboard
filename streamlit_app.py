import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from streamlit_option_menu import option_menu
import os
import joblib

# --- Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ ---
try:
    from sklearn.preprocessing import MinMaxScaler
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import Dense, LSTM, Dropout
    from tensorflow.keras.callbacks import EarlyStopping
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
try:
    from data.saudi_tickers import STOCKS_DB
except ImportError:
    st.error("ğŸš¨ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯.")
    st.stop()

TICKERS = {item['symbol']: item['name'] for item in STOCKS_DB}

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ---
if not os.path.exists('ai_mind'): os.makedirs('ai_mind')

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="TASI AI Tuner", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    .stApp { background-color: #0e1117; color: #e0e0e0; }
    div.stButton > button {
        background: linear-gradient(90deg, #d500f9, #651fff); color: white; border: none;
        padding: 12px; width: 100%; border-radius: 8px; font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© ---
selected_tab = option_menu(
    menu_title=None,
    options=["Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "ğŸ§  Ø¶Ø¨Ø· Ø§Ù„Ø¹Ù‚Ù„ (Bias/Variance)", "Ø§Ù„Ø´Ø§Ø±Øª Ø§Ù„ÙÙ†ÙŠ"],
    icons=["house", "sliders", "graph-up"],
    default_index=1,
    orientation="horizontal",
    styles={"container": {"background-color": "transparent"}, "nav-link-selected": {"background-color": "#651fff"}}
)

# --- 3. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© (Hyperparameters) ---
with st.sidebar:
    st.header("ğŸ›ï¸ Ø¶Ø¨Ø· Bias/Variance")
    
    st.info("ğŸ’¡ **ÙƒÙŠÙ ØªØ¶Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŸ**\n\n- Ù„ØªÙ‚Ù„ÙŠÙ„ **Bias** (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§ ÙŠØªØ¹Ù„Ù…): Ø²Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª (Units) ÙˆØ§Ù„Ù€ Epochs.\n\n- Ù„ØªÙ‚Ù„ÙŠÙ„ **Variance** (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ÙØ¸ ÙÙ‚Ø·): Ø²Ø¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Dropout.")
    
    # ØªØ­ÙƒÙ… ÙÙŠ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    LSTM_UNITS = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ø¹ØµØ¨ÙŠØ© (Complexity)", 20, 200, 50)
    DROPOUT_RATE = st.slider("Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø³ÙŠØ§Ù† (Dropout)", 0.1, 0.5, 0.2, step=0.05)
    EPOCHS = st.slider("Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Epochs)", 5, 100, 20)
    
    st.divider()
    RSI_PERIOD = st.number_input("RSI Period", 14)
    EMA_PERIOD = st.number_input("EMA Period", 20)

# --- 4. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
def calculate_atr(df):
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    ranges = pd.concat([high_low, high_close, low_close], axis=1)
    return ranges.max(axis=1).ewm(alpha=1/14, min_periods=14, adjust=False).mean()

def prepare_data_for_ai(df):
    df = df.copy()
    df['RSI'] = 100 - (100 / (1 + df['Close'].diff().clip(lower=0).ewm(alpha=1/14).mean() / df['Close'].diff().clip(upper=0).abs().ewm(alpha=1/14).mean()))
    df['EMA'] = df['Close'].ewm(span=20).mean()
    df['Box_High'] = df['High'].rolling(window=20).max()
    df['Box_Low'] = df['Low'].rolling(window=20).min()
    df.dropna(inplace=True)
    return df

# --- 5. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Flexible Model) ---
def build_brain_model(input_shape):
    model = Sequential()
    # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ­Ø¯Ø§Øª ØªÙ‚Ù„Ù„ BiasØŒ Ø²ÙŠØ§Ø¯Ø© Dropout ØªÙ‚Ù„Ù„ Variance
    model.add(LSTM(units=LSTM_UNITS, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(DROPOUT_RATE)) 
    
    model.add(LSTM(units=LSTM_UNITS, return_sequences=False))
    model.add(Dropout(DROPOUT_RATE))
    
    model.add(Dense(units=25))
    model.add(Dense(units=1))
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

def train_mind_with_validation(symbol):
    status = st.empty()
    status.info(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù€ Bias/Variance Ù„Ø³Ù‡Ù… {symbol}...")
    
    try:
        df = yf.download(symbol, period="5y", interval="1d", progress=False)
        if len(df) < 500: return None, None, None

        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        df_processed = prepare_data_for_ai(df)
        
        features = ['Close', 'RSI', 'EMA', 'Box_High', 'Box_Low']
        data_values = df_processed[features].values
        
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data_values)
        
        X, y = [], []
        lookback = 60
        for i in range(lookback, len(scaled_data)):
            X.append(scaled_data[i-lookback:i, :])
            y.append(scaled_data[i, 0])
            
        X, y = np.array(X), np.array(y)
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        model = build_brain_model((X.shape[1], X.shape[2]))
        
        # Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ù„Ù„ØªØ­Ù‚Ù‚ (Validation Split) Ù„ÙƒØ´Ù Ø§Ù„Ù€ Variance
        # validation_split=0.2 ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù†Ø§ Ù†Ø®ÙÙŠ 20% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù†Ø®ØªØ¨Ø±Ù‡ Ø¨Ù‡Ø§
        history = model.fit(X, y, batch_size=32, epochs=EPOCHS, validation_split=0.2, verbose=0)
        
        # Ø§Ù„Ø­ÙØ¸
        safe_sym = symbol.replace(".SR", "")
        model.save(f'ai_mind/{safe_sym}_model.keras')
        joblib.dump(scaler, f'ai_mind/{safe_sym}_scaler.pkl')
        
        status.success("âœ… ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨! Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø£Ø³ÙÙ„.")
        return history, df_processed, scaler
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {e}")
        return None, None, None

# --- 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---

if selected_tab == "ğŸ§  Ø¶Ø¨Ø· Ø§Ù„Ø¹Ù‚Ù„ (Bias/Variance)":
    st.header("ğŸ›ï¸ Ù…Ø®ØªØ¨Ø± Ø¶Ø¨Ø· Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    if not AI_AVAILABLE:
        st.error("Ù…ÙƒØªØ¨Ø§Øª AI Ù…ÙÙ‚ÙˆØ¯Ø©.")
    else:
        c1, c2 = st.columns([3, 1])
        with c1:
            target_stock = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³Ù‡Ù… Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±", list(TICKERS.keys()))
        with c2:
            st.write("")
            st.write("")
            start_train = st.button("ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
            
        if start_train:
            history, df_res, scaler = train_mind_with_validation(target_stock)
            
            if history:
                # --- Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªØ¹Ù„Ù… (Learning Curve) ---
                # 
                loss_train = history.history['loss']
                loss_val = history.history['val_loss']
                epochs_range = range(1, len(loss_train) + 1)
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=list(epochs_range), y=loss_train, mode='lines', name='Training Loss (Ø®Ø·Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨)', line=dict(color='#00e676')))
                fig.add_trace(go.Scatter(x=list(epochs_range), y=loss_val, mode='lines', name='Validation Loss (Ø®Ø·Ø£ Ø§Ù„ØªØ­Ù‚Ù‚)', line=dict(color='#ff2950', dash='dot')))
                
                fig.update_layout(
                    title="Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªØ¹Ù„Ù… (Learning Curve) - ÙƒØ§Ø´Ù Ø§Ù„ØªØ­ÙŠØ² ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†",
                    xaxis_title="Ø§Ù„Ø¯ÙˆØ±Ø§Øª (Epochs)",
                    yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ (Loss)",
                    template="plotly_dark",
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # --- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¢Ù„ÙŠØ§Ù‹ ---
                final_train_loss = loss_train[-1]
                final_val_loss = loss_val[-1]
                gap = final_val_loss - final_train_loss
                
                c_res1, c_res2, c_res3 = st.columns(3)
                c_res1.metric("Ø®Ø·Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨", f"{final_train_loss:.5f}")
                c_res2.metric("Ø®Ø·Ø£ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ø§Ù„ÙˆØ§Ù‚Ø¹)", f"{final_val_loss:.5f}")
                
                # Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø¢Ù„ÙŠ
                if final_train_loss > 0.01:
                    status_msg = "ğŸ”´ High Bias (Underfitting)"
                    advice = "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 'ØºØ¨ÙŠ' Ù‚Ù„ÙŠÙ„Ø§Ù‹. Ø§Ù„Ø­Ù„: Ø²Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ø¹ØµØ¨ÙŠØ© (LSTM Units) Ø£Ùˆ Ø²Ø¯ Ø§Ù„Ù€ Epochs."
                elif gap > 0.005: # ÙØ±Ù‚ ÙƒØ¨ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
                    status_msg = "ğŸŸ  High Variance (Overfitting)"
                    advice = "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 'ÙŠØ­ÙØ¸' Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ø§Ù„Ø­Ù„: Ø²Ø¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Dropout Ø£Ùˆ Ù‚Ù„Ù„ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø´Ø¨ÙƒØ©."
                else:
                    status_msg = "ğŸŸ¢ Balanced Model (Ù…Ù…ØªØ§Ø²)"
                    advice = "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆØ§Ø²Ù† ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!"
                
                c_res3.metric("Ø§Ù„Ø­Ø§Ù„Ø©", status_msg)
                st.info(f"ğŸ’¡ **Ø§Ù„ØªØ´Ø®ÙŠØµ:** {advice}")

elif selected_tab == "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©":
    st.info("Ø§Ù†ØªÙ‚Ù„ Ù„ØªØ¨ÙˆÙŠØ¨ 'Ø¶Ø¨Ø· Ø§Ù„Ø¹Ù‚Ù„' Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
