import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from streamlit_option_menu import option_menu
from scipy.signal import argrelextrema
import os
import joblib
import time

# --- Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ (Ù…Ø¹ Ø­Ù…Ø§ÙŠØ©) ---
try:
    from sklearn.preprocessing import MinMaxScaler
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import Dense, LSTM, Dropout
    from tensorflow.keras.callbacks import EarlyStopping
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
try:
    from data.saudi_tickers import STOCKS_DB
except ImportError:
    try:
        from saudi_tickers import STOCKS_DB
    except ImportError:
        st.error("ğŸš¨ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯.")
        st.stop()

TICKERS = {item['symbol']: item['name'] for item in STOCKS_DB}
SECTORS = {item['name']: item['sector'] for item in STOCKS_DB}

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ù„Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ---
if not os.path.exists('ai_mind'):
    os.makedirs('ai_mind')

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="TASI AI Mind", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    .stApp { background-color: #0e1117; color: #e0e0e0; }
    div.stButton > button {
        background: linear-gradient(90deg, #6200ea, #3700b3); color: white; border: none;
        padding: 12px; width: 100%; border-radius: 8px; font-weight: bold;
    }
    div[data-testid="stMetric"] { background-color: #1d212b; border-radius: 10px; border: 1px solid #333; }
</style>
""", unsafe_allow_html=True)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© ---
selected_tab = option_menu(
    menu_title=None,
    options=["Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (AI)", "Ø§Ù„Ø´Ø§Ø±Øª Ø§Ù„ÙÙ†ÙŠ"],
    icons=["house", "cpu", "graph-up"],
    default_index=1,
    orientation="horizontal",
    styles={"container": {"background-color": "transparent"}, "nav-link-selected": {"background-color": "#6200ea"}}
)

# --- 3. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©")
    RSI_PERIOD = st.number_input("RSI Period", 14, 30, 24)
    EMA_PERIOD = st.number_input("EMA Trend", 10, 200, 20)
    ATR_MULT = st.number_input("ATR Multiplier", 1.0, 3.0, 1.5)
    
    st.divider()
    st.header("ğŸ§  Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡")
    EPOCHS = st.slider("Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Epochs)", 5, 50, 15)
    LOOKBACK = st.slider("Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ (Ø£ÙŠØ§Ù…)", 30, 90, 60)

# --- 4. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„ÙÙ†ÙŠØ© ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
def calculate_atr(df):
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    ranges = pd.concat([high_low, high_close, low_close], axis=1)
    return ranges.max(axis=1).ewm(alpha=1/14, min_periods=14, adjust=False).mean()

def prepare_data_for_ai(df):
    """
    ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø­ÙŠØ« ÙŠØªØ¹Ù„Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ù…Ù†:
    1. Ø§Ù„Ø³Ø¹Ø± (Close)
    2. Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (RSI, EMA)
    3. Ø­Ø¯ÙˆØ¯ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ (Box Levels) - Ø£Ù‡Ù… Ù…ÙŠØ²Ø©
    """
    df = df.copy()
    # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
    df['RSI'] = 100 - (100 / (1 + df['Close'].diff().clip(lower=0).ewm(alpha=1/14).mean() / df['Close'].diff().clip(upper=0).abs().ewm(alpha=1/14).mean()))
    df['EMA'] = df['Close'].ewm(span=20).mean()
    df['ATR'] = calculate_atr(df)
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ù„ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡ ÙƒØ£Ø±Ù‚Ø§Ù…
    # (Ø§Ù„Ø°ÙƒØ§Ø¡ Ù„Ø§ ÙŠØ±Ù‰ Ø§Ù„Ø±Ø³Ù…ØŒ Ø¨Ù„ ÙŠØ±Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…ØŒ Ù„Ø°Ø§ Ù†Ø¹Ø·ÙŠÙ‡ Ø£Ø¹Ù„Ù‰ ÙˆØ£Ø¯Ù†Ù‰ Ø³Ø¹Ø± Ù„Ø¢Ø®Ø± 20 ÙŠÙˆÙ… ÙƒØ¯Ù„Ø§Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚)
    df['Box_High'] = df['High'].rolling(window=20).max()
    df['Box_Low'] = df['Low'].rolling(window=20).min()
    
    df.dropna(inplace=True)
    return df

# --- 5. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (The Brain) ---

def build_brain_model(input_shape):
    """Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© LSTM Ù…ØªÙ‚Ø¯Ù…Ø©"""
    model = Sequential()
    # Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ø³ØªÙŠØ¹Ø§Ø¨ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
    model.add(LSTM(units=100, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2)) # Ù…Ù†Ø¹ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØµÙ…
    
    # Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø±Ø¨Ø· Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø¨Ø¨Ø¹Ø¶Ù‡Ø§
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dropout(0.2))
    
    # Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙÙƒÙŠØ± (Dense)
    model.add(Dense(units=25))
    model.add(Dense(units=1)) # Ø§Ù„Ù…Ø®Ø±Ø¬: Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

def train_mind(symbol):
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù‚Ù„ ÙˆØ­ÙØ¸Ù‡"""
    status = st.empty()
    status.info(f"Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ 5 Ø³Ù†ÙˆØ§Øª Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù‚Ù„ Ø¹Ù„Ù‰ {symbol}...")
    
    try:
        df = yf.download(symbol, period="5y", interval="1d", progress=False)
        if len(df) < 500:
            st.error("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
            return None

        # ØªÙ†Ø¸ÙŠÙ ÙˆØªØ¬Ù‡ÙŠØ²
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        df_processed = prepare_data_for_ai(df)
        
        # Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªÙŠ Ø³ÙŠØªØ¹Ù„Ù… Ù…Ù†Ù‡Ø§ (Features)
        # Ø§Ù„Ø³Ø¹Ø± + RSI + EMA + Ø­Ø¯ÙˆØ¯ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚
        features = ['Close', 'RSI', 'EMA', 'Box_High', 'Box_Low']
        data_values = df_processed[features].values
        
        # Ø§Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ (Scaling) Ø¨ÙŠÙ† 0 Ùˆ 1 (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©)
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data_values)
        
        # ØªÙƒÙˆÙŠÙ† Ø³Ù„Ø§Ø³Ù„ Ø²Ù…Ù†ÙŠØ© (X, y)
        X_train, y_train = [], []
        for i in range(LOOKBACK, len(scaled_data)):
            X_train.append(scaled_data[i-LOOKBACK:i, :]) # Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª: Ø¢Ø®Ø± 60 ÙŠÙˆÙ… Ø¨ÙƒÙ„ Ù…ÙŠØ²Ø§ØªÙ‡Ø§
            y_train.append(scaled_data[i, 0]) # Ø§Ù„Ù‡Ø¯Ù: Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ù„Ù„ÙŠÙˆÙ… Ø§Ù„ØªØ§Ù„ÙŠ
            
        X_train, y_train = np.array(X_train), np.array(y_train)
        
        # Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        status.info(f"ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ ÙŠØªØ¯Ø±Ø¨ Ø§Ù„Ø¢Ù†... (Epochs: {EPOCHS})")
        model = build_brain_model((X_train.shape[1], X_train.shape[2]))
        
        # Early Stopping: ÙŠÙˆÙ‚Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ­Ø³Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª
        early_stop = EarlyStopping(monitor='loss', patience=3)
        
        model.fit(X_train, y_train, batch_size=32, epochs=EPOCHS, callbacks=[early_stop], verbose=0)
        
        # Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¹Ù‚Ù„
        safe_sym = symbol.replace(".SR", "")
        model.save(f'ai_mind/{safe_sym}_model.keras')
        joblib.dump(scaler, f'ai_mind/{safe_sym}_scaler.pkl')
        
        status.success("âœ… ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ø§Ù„Ø®Ø¨Ø±Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ø¹Ù‚Ù„!")
        return df_processed
        
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
        return None

def consult_mind(symbol):
    """Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø¹Ù‚Ù„ Ù„Ù„ØªÙˆÙ‚Ø¹"""
    safe_sym = symbol.replace(".SR", "")
    model_path = f'ai_mind/{safe_sym}_model.keras'
    scaler_path = f'ai_mind/{safe_sym}_scaler.pkl'
    
    if not os.path.exists(model_path):
        return None, "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù‚Ù„ Ù…Ø¯Ø±Ø¨ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ù‡Ù…. Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙˆÙ„Ø§Ù‹."
    
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ù‚Ù„
        model = load_model(model_path)
        scaler = joblib.load(scaler_path)
        
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ø¶Ø±
        df = yf.download(symbol, period="6mo", interval="1d", progress=False)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        df_processed = prepare_data_for_ai(df)
        
        # Ø£Ø®Ø° Ø¢Ø®Ø± ÙØªØ±Ø© (Ø§Ù„Ø­Ø§Ø¶Ø±)
        last_days = df_processed[['Close', 'RSI', 'EMA', 'Box_High', 'Box_Low']].values[-LOOKBACK:]
        
        if len(last_days) < LOOKBACK: return None, "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© ØºÙŠØ± ÙƒØ§ÙÙŠØ©."
        
        # ØªØ¬Ù‡ÙŠØ² ÙˆØªÙˆÙ‚Ø¹
        last_days_scaled = scaler.transform(last_days)
        X_test = np.array([last_days_scaled]) # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ 3D array
        
        predicted_scaled = model.predict(X_test, verbose=0)
        
        # Ø¹ÙƒØ³ Ø§Ù„ØªØ­Ø¬ÙŠÙ… Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±
        # Ù†Ù†Ø´Ø¦ Ù…ØµÙÙˆÙØ© ÙˆÙ‡Ù…ÙŠØ© Ø¨Ù†ÙØ³ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù€ scaler Ù„Ø¹ÙƒØ³ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙ‚Ø·
        dummy = np.zeros((1, 5)) 
        dummy[0, 0] = predicted_scaled[0, 0]
        predicted_price = scaler.inverse_transform(dummy)[0, 0]
        
        return predicted_price, df_processed['Close'].iloc[-1]
        
    except Exception as e:
        return None, str(e)

# --- 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ´ØºÙŠÙ„ ---

if selected_tab == "ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (AI)":
    st.title("ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (Deep Learning LSTM)")
    st.markdown("""
    Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… **Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚** Ù„ÙÙ‡Ù… Ø³Ù„ÙˆÙƒ Ø§Ù„Ø³Ù‡Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚.
    ÙŠÙ‚ÙˆÙ… Ø¨Ø­ÙØ¸ Ù…Ø§ ØªØ¹Ù„Ù…Ù‡ ÙÙŠ Ù…Ø¬Ù„Ø¯ `ai_mind` Ù„ÙŠØ¹ÙˆØ¯ Ø¥Ù„ÙŠÙ‡ Ù„Ø§Ø­Ù‚Ø§Ù‹.
    """)
    
    if not AI_AVAILABLE:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (tensorflow, scikit-learn) ÙÙŠ Ù…Ù„Ù requirements.txt")
    else:
        col_sel, col_act = st.columns([2, 1])
        with col_sel:
            target_stock = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³Ù‡Ù…", list(TICKERS.keys()), format_func=lambda x: f"{TICKERS[x]} ({x})")
        
        with col_act:
            st.write("") # Spacer
            st.write("")
            train_btn = st.button("ğŸ”´ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹Ù‚Ù„ (Train)")
            predict_btn = st.button("ğŸ”® Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø¹Ù‚Ù„ (Predict)")
            
        if train_btn:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©..."):
                _ = train_mind(target_stock)
                
        if predict_btn:
            with st.spinner("Ø§Ù„Ø¹Ù‚Ù„ ÙŠÙÙƒØ±..."):
                pred, current = consult_mind(target_stock)
                if pred:
                    change = ((pred - current) / current) * 100
                    color = "green" if change > 0 else "red"
                    direction = "ØµØ¹ÙˆØ¯ ğŸ“ˆ" if change > 0 else "Ù‡Ø¨ÙˆØ· ğŸ“‰"
                    
                    st.divider()
                    c1, c2, c3 = st.columns(3)
                    c1.metric("Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ", f"{current:.2f}")
                    c2.metric("Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (ØºØ¯Ø§Ù‹)", f"{pred:.2f}", f"{change:.2f}%")
                    c3.markdown(f"### Ø§Ù„Ø§ØªØ¬Ø§Ù‡: :{color}[{direction}]")
                    
                    # Ù†ØµÙŠØ­Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡
                    st.info(f"ğŸ’¡ **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù‚Ù„:** Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³Ù‡Ù… Ù…Ø¹ Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙÙŠ Ø¢Ø®Ø± {LOOKBACK} ÙŠÙˆÙ…ØŒ ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… ØªØ­Ø±ÙƒØ§Ù‹ Ø¨Ù†Ø³Ø¨Ø© {change:.2f}%.")
                else:
                    st.warning(f"ØªÙ†Ø¨ÙŠÙ‡: {current}") # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£

# --- ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡) ---
elif selected_tab == "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©":
    st.title("ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ø³ÙˆÙ‚ (Analysis)")
    if st.button("ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        # ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¨Ø³Ø· Ø§Ù„Ø®Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        pass # (ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø³Ø® ÙƒÙˆØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ù…Ù† Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª)
    st.info("Ø§Ù†ØªÙ‚Ù„ Ù„ØªØ¨ÙˆÙŠØ¨ 'Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ' Ù„ØªØ¬Ø±Ø¨Ø© Ù…ÙŠØ²Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.")

