import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from datetime import datetime, timedelta

# ---------------------------------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªÙ‡ÙŠØ¦Ø©
# ---------------------------------------------------------
st.set_page_config(
    page_title="Ù…Ø­Ù„Ù„ ØªØ§Ø³ÙŠ Ø§Ù„Ø°ÙƒÙŠ (TASI AI Analyzer)",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ®ØµÙŠØµ CSS Ù„Ø¯Ø¹Ù… Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø± (RTL)
st.markdown("""
<style>
    .main { direction: rtl; }
    h1, h2, h3, h4, p, div { font-family: 'Tajawal', sans-serif; text-align: right; }
    .stMetric { text-align: right !important; direction: rtl; }
    .stDataFrame { direction: ltr; } 
    div[data-testid="stSidebar"] { text-align: right; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 2. ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© (Helpers)
# ---------------------------------------------------------
def compute_rsi(series, period=14):
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±"""
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

# ---------------------------------------------------------
# 3. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§ (Data Fetching & Cleaning)
# ---------------------------------------------------------

@st.cache_data(ttl=3600)
def get_stock_data(ticker, start_date, end_date):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù‡Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ ØµØ§Ø±Ù… Ù„Ù„Ø£Ø¹Ù…Ø¯Ø©"""
    if not ticker.endswith('.SR'):
        ticker = f"{ticker}.SR"
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
    try:
        df = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=False)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ØµØ¯Ø±: {e}")
        return None

    # --- Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© MultiIndex ÙˆØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ---
    if isinstance(df.columns, pd.MultiIndex):
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ³Ø·ÙŠØ­ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        try:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ticker Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ø§Ù†ÙŠØŒ Ù†Ø­Ø°ÙÙ‡
            df.columns = df.columns.get_level_values(0)
        except:
            pass
    
    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ØªÙƒØ±Ø§Ø± ÙÙŠ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø§Ù„Ø­Ù„ Ø§Ù„Ø¬Ø°Ø±ÙŠ Ù„Ù„Ø®Ø·Ø£)
    df = df.loc[:, ~df.columns.duplicated()]

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    if df.empty or 'Close' not in df.columns:
        return None
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ù„Ù„ØªØ£ÙƒØ¯
    cols_to_numeric = ['Open', 'High', 'Low', 'Close', 'Volume']
    for col in cols_to_numeric:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
    df['SMA_50'] = df['Close'].rolling(window=50).mean()
    df['SMA_200'] = df['Close'].rolling(window=200).mean()
    df['RSI'] = compute_rsi(df['Close'], 14)
    
    # Bollinger Bands
    df['BB_High'] = df['Close'].rolling(20).mean() + (df['Close'].rolling(20).std() * 2)
    df['BB_Low'] = df['Close'].rolling(20).mean() - (df['Close'].rolling(20).std() * 2)
    
    return df

@st.cache_data(ttl=3600)
def get_global_indices(start_date, end_date):
    """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©"""
    tickers = {
        'S&P 500': '^GSPC',
        'Brent Oil': 'BZ=F',
        'Gold': 'GC=F',
        'USD Index': 'DX-Y.NYB',
        'US 10Y Bond': '^TNX'
    }
    
    global_df = pd.DataFrame()
    
    for name, sym in tickers.items():
        try:
            data = yf.download(sym, start=start_date, end=end_date, progress=False, auto_adjust=False)
            
            # ØªÙ†Ø¸ÙŠÙ MultiIndex
            if isinstance(data.columns, pd.MultiIndex):
                data.columns = data.columns.get_level_values(0)
            
            data = data.loc[:, ~data.columns.duplicated()]

            if not data.empty and 'Close' in data.columns:
                temp = data[['Close']].rename(columns={'Close': name})
                if global_df.empty:
                    global_df = temp
                else:
                    global_df = global_df.join(temp, how='outer')
        except Exception:
            continue
            
    # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø¹Ø·Ù„Ø§Øª)
    global_df.fillna(method='ffill', inplace=True)
    global_df.fillna(method='bfill', inplace=True)
    
    return global_df

def prepare_dataset(local_df, global_df):
    """Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
    # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    combined = local_df.join(global_df, how='inner')
    
    # ØªÙ†Ø¸ÙŠÙ ÙÙˆØ±ÙŠ Ù„Ù„ØªÙƒØ±Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬
    combined = combined.loc[:, ~combined.columns.duplicated()]
    
    # Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª (Feature Engineering)
    global_cols = global_df.columns
    for col in global_cols:
        if col in combined.columns:
            combined[f'{col}_Pct'] = combined[col].pct_change()
            combined[f'{col}_Lag1'] = combined[f'{col}_Pct'].shift(1)
            combined[f'{col}_Lag3'] = combined[f'{col}_Pct'].shift(3)

    combined.dropna(inplace=True)
    return combined

# ---------------------------------------------------------
# 4. Ø§Ù„Ù†Ù…Ø°Ø¬Ø© (Machine Learning)
# ---------------------------------------------------------

def train_prediction_model(df, target_col='Close', horizon=30):
    """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost"""
    # 1. ØªÙ†Ø¸ÙŠÙ ÙˆÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡
    data = df.copy()
    data = data.loc[:, ~data.columns.duplicated()] # Ø®Ø·ÙˆØ© Ø£Ù…Ø§Ù† Ø¥Ø¶Ø§ÙÙŠØ©
    
    if target_col not in data.columns:
        return None, 0, 0, 0, pd.DataFrame(), [], []

    # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡Ø¯Ù (Target)
    try:
        horizon = int(horizon)
        data['Target'] = data[target_col].shift(-horizon)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù‡Ø¯Ù: {e}")
        return None, 0, 0, 0, pd.DataFrame(), [], []

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª (Features) - Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø© Ù„Ù„ØªÙ†Ø¨Ø¤
    drop_cols = ['Target', 'Open', 'High', 'Low', 'Volume', 'Adj Close']
    feature_cols = [c for c in data.columns if c not in drop_cols]
    
    data.dropna(inplace=True)
    
    if len(data) < 50: # Ù„Ø§ ÙŠÙƒÙÙŠ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        st.warning("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
        return None, 0, 0, 0, pd.DataFrame(), [], []

    X = data[feature_cols]
    y = data['Target']
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    split_idx = int(len(X) * 0.85)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
    
    # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = XGBRegressor(
        n_estimators=150, 
        learning_rate=0.05, 
        max_depth=4, 
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    preds = model.predict(X_test)
    score = r2_score(y_test, preds)
    mae = mean_absolute_error(y_test, preds)
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ (Ø¢Ø®Ø± ØµÙ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©)
    last_row_features = X.iloc[[-1]]
    future_pred = model.predict(last_row_features)[0]
    
    # Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª
    importance = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    return model, score, mae, future_pred, importance, preds, y_test

# ---------------------------------------------------------
# 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Main Layout)
# ---------------------------------------------------------

st.sidebar.header("ğŸ“Š Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
ticker_input = st.sidebar.text_input("Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù…", value="1120", help="Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ù…Ø² Ø¨Ø¯ÙˆÙ† .SR")
years_back = st.sidebar.slider("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (Ø³Ù†ÙˆØ§Øª)", 1, 10, 3)
forecast_days = st.sidebar.selectbox("ÙØªØ±Ø© Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø£ÙŠØ§Ù…)", [7, 14, 30, 90], index=2)
include_global = st.sidebar.checkbox("ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©", value=True)

if st.sidebar.button("ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ğŸš€"):
    
    end_date = datetime.now()
    start_date = end_date - timedelta(days=years_back*365)
    
    with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'):
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        local_df = get_stock_data(ticker_input, start_date, end_date)
        
        if local_df is None:
            st.error(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ù…Ø² {ticker_input}. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø±Ù…Ø².")
        else:
            # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© ÙˆØ¯Ù…Ø¬Ù‡Ø§
            full_df = local_df.copy()
            if include_global:
                global_df = get_global_indices(start_date, end_date)
                full_df = prepare_dataset(local_df, global_df)
            else:
                full_df = local_df.dropna()

            # ---------------------------
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            # ---------------------------
            st.title(f"ØªØ­Ù„ÙŠÙ„ Ø³Ù‡Ù…: {ticker_input} (TASI)")
            
            # KPIs
            last_close = local_df['Close'].iloc[-1]
            prev_close = local_df['Close'].iloc[-2]
            chg = last_close - prev_close
            chg_pct = (chg / prev_close) * 100
            
            kpi1, kpi2, kpi3, kpi4 = st.columns(4)
            kpi1.metric("Ø¢Ø®Ø± Ø³Ø¹Ø±", f"{last_close:.2f}", f"{chg_pct:.2f}%")
            kpi2.metric("SMA 200", f"{local_df['SMA_200'].iloc[-1]:.2f}")
            kpi3.metric("RSI (14)", f"{local_df['RSI'].iloc[-1]:.1f}")
            vol = local_df['Volume'].iloc[-1]
            kpi4.metric("Ø§Ù„Ø­Ø¬Ù…", f"{vol:,.0f}")
            
            # Tabs
            tab_tech, tab_global, tab_ai = st.tabs(["ğŸ“ˆ Ø§Ù„Ø±Ø³Ù… Ø§Ù„ÙÙ†ÙŠ", "ğŸŒ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª", "ğŸ¤– ØªÙˆÙ‚Ø¹Ø§Øª AI"])
            
            # Tab 1: Technical
            with tab_tech:
                fig = go.Figure()
                fig.add_trace(go.Candlestick(x=local_df.index,
                                open=local_df['Open'], high=local_df['High'],
                                low=local_df['Low'], close=local_df['Close'], name='Ø§Ù„Ø³Ø¹Ø±'))
                fig.add_trace(go.Scatter(x=local_df.index, y=local_df['BB_High'], line=dict(color='gray', width=1, dash='dot'), name='Bollinger High'))
                fig.add_trace(go.Scatter(x=local_df.index, y=local_df['BB_Low'], line=dict(color='gray', width=1, dash='dot'), name='Bollinger Low'))
                fig.update_layout(height=500, margin=dict(l=0, r=0, t=30, b=0))
                st.plotly_chart(fig, use_container_width=True)
            
            # Tab 2: Global Correlations
            with tab_global:
                if include_global and 'S&P 500' in full_df.columns:
                    corr_cols = ['Close', 'S&P 500', 'Brent Oil', 'Gold', 'US 10Y Bond']
                    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù‚Ø¨Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
                    avail_cols = [c for c in corr_cols if c in full_df.columns]
                    
                    corr_matrix = full_df[avail_cols].corr()
                    
                    fig_corr = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r', title="Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·")
                    st.plotly_chart(fig_corr, use_container_width=True)
                    
                    st.caption("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† 1 ØªØ¹Ù†ÙŠ Ø¹Ù„Ø§Ù‚Ø© Ø·Ø±Ø¯ÙŠØ© Ù‚ÙˆÙŠØ© (ÙŠØªØ­Ø±ÙƒÙˆÙ† Ù…Ø¹Ø§Ù‹)ØŒ ÙˆØ§Ù„Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† -1 ØªØ¹Ù†ÙŠ Ø¹Ù„Ø§Ù‚Ø© Ø¹ÙƒØ³ÙŠØ©.")
                else:
                    st.info("Ù„Ù… ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ø£Ùˆ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„Ù‡Ø§.")

            # Tab 3: AI Prediction
            with tab_ai:
                st.subheader(f"ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ÙØªØ±Ø© {forecast_days} ÙŠÙˆÙ…")
                
                model, score, mae, future_pred, importance, preds, y_test_vals = train_prediction_model(full_df, horizon=forecast_days)
                
                if model:
                    col_res1, col_res2 = st.columns(2)
                    with col_res1:
                        st.success(f"Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: **{future_pred:.2f} Ø±ÙŠØ§Ù„**")
                        diff_pred = future_pred - last_close
                        st.metric("Ø§Ù„ØªØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹", f"{diff_pred:.2f}", f"{(diff_pred/last_close)*100:.2f}%")
                    
                    with col_res2:
                        st.write("Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:")
                        st.progress(max(0.0, min(1.0, score)))
                        st.caption(f"RÂ² Score: {score:.2f} | Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…ØªÙˆØ³Ø·: {mae:.2f}")

                    # Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙˆÙ‚Ø¹
                    st.markdown("---")
                    st.write("##### Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø©:")
                    st.plotly_chart(px.bar(importance.head(7), x='Importance', y='Feature', orientation='h'), use_container_width=True)
                else:
                    st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©).")

else:
    st.info("Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù… ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ù…Ø«Ù„ 1120 Ù„Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø£Ùˆ 2222 Ù„Ø£Ø±Ø§Ù…ÙƒÙˆ).")
